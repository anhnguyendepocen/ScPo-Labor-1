<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Selection Lab</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-fork-ribbon-css/0.2.0/gh-fork-ribbon.min.css" />
<!--[if lt IE 9]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-fork-ribbon-css/0.2.0/gh-fork-ribbon.ie.min.css" />
<![endif]-->

  
<!-- Bootstrap core CSS -->
<link href="site_libs/bootstrap-3.3.5/css/simplex.css" rel="stylesheet">


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; } /* Alert */
code span.an { color: #008000; } /* Annotation */
code span.at { } /* Attribute */
code span.bu { } /* BuiltIn */
code span.cf { color: #0000ff; } /* ControlFlow */
code span.ch { color: #008080; } /* Char */
code span.cn { } /* Constant */
code span.co { color: #008000; } /* Comment */
code span.cv { color: #008000; } /* CommentVar */
code span.do { color: #008000; } /* Documentation */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.im { } /* Import */
code span.in { color: #008000; } /* Information */
code span.kw { color: #0000ff; } /* Keyword */
code span.op { } /* Operator */
code span.ot { color: #ff4000; } /* Other */
code span.pp { color: #ff4000; } /* Preprocessor */
code span.sc { color: #008080; } /* SpecialChar */
code span.ss { color: #008080; } /* SpecialString */
code span.st { color: #008080; } /* String */
code span.va { } /* Variable */
code span.vs { color: #008080; } /* VerbatimString */
code span.wa { color: #008000; font-weight: bold; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">ScPo-GradLabour</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Home
  </a>
</li>
<li>
  <a href="notes.html">
    <span class="fa fa-calendar-check-o"></span>
     
    Topics
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-pencil-square-o"></span>
     
    Homeworks
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="static-labor-supply.html">Static LS</a>
    </li>
    <li>
      <a href="hw-lifecycle.html">Lifecycle Model</a>
    </li>
    <li>
      <a href="estimate-dynamic-LS.html">Dynamic Discrete Choice</a>
    </li>
    <li>
      <a href="ShimerSmith.html">Search and Matching</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-wrench"></span>
     
    Labs
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="lab-selection.html">Selection Model</a>
    </li>
    <li>
      <a href="lab-akm.html">Estimating AKM</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/floswald/ScPo-Labor">
    <span class="fa fa-github"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/floswald/ScPo-Labor/issues">
    <span class="fa fa-bug"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Selection Lab</h1>

</div>


<p>In this lab we will study estimation of the Heckman Selection Model. Much of this will be based on the vignette of the <a href="https://www.jstatsoft.org/article/view/v027i07/v27i07.pdf"><code>sampleSelection</code> package</a>.</p>
<div id="setup" class="section level2">
<h2>Setup</h2>
<p>Just to remind ourselves to last week’s class, we are dealing with two latent processes that can be written as follows, where <span class="math inline">\(o\)</span> is for <em>outcome</em> and <span class="math inline">\(s\)</span> is for <em>selection</em>:</p>
<p><span class="math display">\[\begin{align}
y_i^s &amp;= \begin{cases}
0 &amp; \text{if }\beta^s x_i^s + \varepsilon_i^s &lt; 0 \\
1 &amp; \text{else.}
\end{cases} \\
y_i^o &amp;= \begin{cases}
0 &amp; \text{if }y_i^s = 0 \\
\beta^o x_i^o + \varepsilon_i^o &amp; \text{else.}
\end{cases}
\end{align}\]</span></p>
<p>This means that we only observe outcome <span class="math inline">\(y_i^o\)</span> if <span class="math inline">\(i\)</span> was selected into the sample via <span class="math inline">\(\beta^s x_i^s + \varepsilon_i^s &gt; 0\)</span>. Our population regression function looks like</p>
<p><span class="math display">\[
E[y^o | x^o,x^s,y^s=1] = \beta^o x^o + E[\varepsilon^o | \varepsilon^s \geq - \beta^s x^s]
\]</span></p>
<p>which is biased if <span class="math inline">\(E[\varepsilon^o | \varepsilon^s \geq - \beta^s x^s] \neq 0\)</span>. Notice that <span class="math inline">\(E[\varepsilon^o | \varepsilon^s \geq - \beta^s x^s]\)</span> is often called the <strong>control function</strong>.</p>
<div id="joint-normality-of-errors" class="section level3">
<h3>Joint Normality of Errors</h3>
<p>We proceed by assuming joint normality:</p>
<p><span class="math display">\[\begin{equation}
\left[ \begin{array}{c} \varepsilon^s \\ \varepsilon^o \end{array} \right] \sim 
N \left( \left[ \begin{array}{c} 0 \\ 0 \end{array} \right] , \left[ \begin{array}{cc} 1 &amp; \rho \\ \rho &amp; \sigma^2 \end{array} \right]\right)
\end{equation}\]</span></p>
<p>Notice that we impose the scale normalization that <span class="math inline">\(Var(\varepsilon^s) = 1\)</span>. With this assumption, we can then proceed to estimate the selection equation by probit, and evaluate the obtained coefficients <span class="math inline">\(\beta_s\)</span> in the <em>inverse mills ratio</em> as follows:</p>
<p><span class="math display">\[
y_i^o = \beta^o x_i^o + E[\varepsilon^o | \varepsilon_i^s \geq - \beta^s x_i^s] + \eta_i \equiv \beta^o x_i^o + \rho \sigma \lambda(\beta^s x_i^s) + \eta_i
\]</span> where <span class="math inline">\(E[\eta|x^o,x^s]=0\)</span> and <span class="math inline">\(\lambda(\cdot) = \frac{\phi(\cdot)}{\Phi(\cdot)}\)</span> is the inverse mills ratio.</p>
</div>
</div>
<div id="synthetic-data" class="section level2">
<h2>Synthetic Data</h2>
<p>Let’s generate a data set with <span class="math inline">\(\beta_0^j=0,\beta_1^j=1,j=s,o\)</span> i.e. all intercepts zero and a single regressor in each equation with slope 1 and <strong>with</strong> a valid exclusion restriction:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">n =<span class="st"> </span><span class="dv">2000</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2">eps &lt;-<span class="st"> </span><span class="kw">rmvnorm</span>(n, <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>,<span class="op">-</span><span class="fl">0.7</span>,<span class="op">-</span><span class="fl">0.7</span>,<span class="dv">1</span>), <span class="dv">2</span>, <span class="dv">2</span>))</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">xs &lt;-<span class="st"> </span><span class="kw">runif</span>(n)</a>
<a class="sourceLine" id="cb1-4" data-line-number="4">ys &lt;-<span class="st"> </span>xs <span class="op">+</span><span class="st"> </span>eps[,<span class="dv">1</span>] <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5">xo &lt;-<span class="st"> </span><span class="kw">runif</span>(n)</a>
<a class="sourceLine" id="cb1-6" data-line-number="6">yoX &lt;-<span class="st"> </span>xo <span class="op">+</span><span class="st"> </span>eps[,<span class="dv">2</span>]  <span class="co"># exclusion: use xo, not xs!</span></a>
<a class="sourceLine" id="cb1-7" data-line-number="7">yo &lt;-<span class="st"> </span>yoX<span class="op">*</span>(ys <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb1-8" data-line-number="8"></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="co"># quick check</span></a>
<a class="sourceLine" id="cb1-10" data-line-number="10">m =<span class="st"> </span><span class="kw">selection</span>(ys <span class="op">~</span><span class="st"> </span>xs, yo <span class="op">~</span><span class="st"> </span>xo)</a>
<a class="sourceLine" id="cb1-11" data-line-number="11"><span class="kw">summary</span>(m)</a></code></pre></div>
<pre><code>## --------------------------------------------
## Tobit 2 model (sample selection model)
## Maximum Likelihood estimation
## Newton-Raphson maximisation, 3 iterations
## Return code 2: successive function values within tolerance limit
## Log-Likelihood: -2929.434 
## 2000 observations (634 censored and 1366 observed)
## 6 free parameters (df = 1994)
## Probit selection equation:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.01460    0.05226  -0.279     0.78    
## xs           1.03058    0.09437  10.920   &lt;2e-16 ***
## Outcome equation:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.04622    0.06139   0.753    0.452    
## xo           0.96638    0.08071  11.974   &lt;2e-16 ***
##    Error terms:
##       Estimate Std. Error t value Pr(&gt;|t|)    
## sigma  1.00448    0.03580   28.05   &lt;2e-16 ***
## rho   -0.73022    0.05669  -12.88   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## --------------------------------------------</code></pre>
<p>Results:</p>
<ul>
<li>Estimates look correct (there is of course small sample bias)
<ul>
<li>intercepts are zero</li>
<li>slopes are 1</li>
<li><span class="math inline">\(\sigma^2=1\)</span></li>
<li><span class="math inline">\(\rho = -0.7\)</span></li>
</ul></li>
</ul>
<p><span class="btn btn-success btn-xs">Task 1. </span> Make a plot that looks like this:</p>
<p><img src="lab-selection_files/figure-html/gg-1.png" width="672" /></p>
<p>We see that</p>
<ol style="list-style-type: decimal">
<li>Observed outcomes are lower than unobserved ones (result of <span class="math inline">\(\rho &lt;1\)</span>)</li>
<li>OLS intercept is downward biased</li>
<li>OLS slope is unbiased because <span class="math inline">\(E[\varepsilon^o | \varepsilon^s \geq - \beta^s x^s]\)</span> is independent of <span class="math inline">\(x^o\)</span></li>
</ol>
<div id="inverse-mills-ratio" class="section level3">
<h3>Inverse Mills Ratio</h3>
<p>Let us investigate the inverse mills ratio a bit now. We know that in theory, it should be a convex function that becomes linear at high values of the index.</p>
<p><span class="btn btn-success btn-xs">Task 2. </span> Plot the inverse mills ratio!</p>
<p><img src="lab-selection_files/figure-html/mills-theory-1.png" width="672" /></p>
<p>And in our data?</p>
<p><span class="btn btn-success btn-xs">Task 3. </span> Add our data values for <span class="math inline">\(\lambda\)</span> to your previous plot.</p>
<p><img src="lab-selection_files/figure-html/mills-1.png" width="672" /></p>
<p>So we can see that the values of our single index for selection <span class="math inline">\(\beta^s x^s\)</span> falls well within the range where <span class="math inline">\(\lambda\)</span> is nonlinear in this case.</p>
</div>
<div id="no-exclusion-restriction" class="section level3">
<h3>No Exclusion Restriction</h3>
<p>We <em>could</em> rely on functional form identification only. Let’s try this: just regenerate the data without exclusion restriction.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1">yoX &lt;-<span class="st"> </span>xs <span class="op">+</span><span class="st"> </span>eps[,<span class="dv">2</span>]  <span class="co"># no exclusion restriction! xs both in selection and outcome!</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">yo &lt;-<span class="st"> </span>yoX<span class="op">*</span>(ys <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">m2 =<span class="st"> </span><span class="kw">selection</span>(ys <span class="op">~</span><span class="st"> </span>xs, yo <span class="op">~</span><span class="st"> </span>xs)</a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="kw">summary</span>(m2)</a></code></pre></div>
<pre><code>## --------------------------------------------
## Tobit 2 model (sample selection model)
## Maximum Likelihood estimation
## Newton-Raphson maximisation, 5 iterations
## Return code 1: gradient close to zero
## Log-Likelihood: -2929.52 
## 2000 observations (634 censored and 1366 observed)
## 6 free parameters (df = 1994)
## Probit selection equation:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.01535    0.05633  -0.273    0.785    
## xs           1.03204    0.10270  10.049   &lt;2e-16 ***
## Outcome equation:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.03285    0.08625   0.381    0.703    
## xs           0.99634    0.09910  10.054   &lt;2e-16 ***
##    Error terms:
##       Estimate Std. Error t value Pr(&gt;|t|)    
## sigma  1.00575    0.03911   25.71   &lt;2e-16 ***
## rho   -0.73237    0.06203  -11.81   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## --------------------------------------------</code></pre>
<p>We are still unbiased! This is a result of the <span class="math inline">\(\lambda\)</span> being non-linear in our case. But we have larger standard errors.</p>
<p><span class="btn btn-success btn-xs">Task 4. </span> Redo our previous plot:</p>
<p><img src="lab-selection_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Results:</p>
<ol style="list-style-type: decimal">
<li>Heckman MLE does still well</li>
<li>OLS is biased for both slope and intercept: Slope as well this time because <span class="math inline">\(E[\varepsilon^o | \varepsilon^s \geq - \beta^s x^s]\)</span> is increasing in <span class="math inline">\(x^s\)</span> (and <span class="math inline">\(x^s=x^o\)</span>)</li>
</ol>
</div>
<div id="standard-errors" class="section level3">
<h3>Standard Errors</h3>
<ul>
<li>The precision in the last estimation was smaller because we lost identifying power from independent variation in <span class="math inline">\(x^s\)</span>, i.e. we had no exclusion restriction.</li>
<li>If we could increase the variation in <span class="math inline">\(x^s \beta^s\)</span>, we could regain some of that power.</li>
</ul>
<p><span class="btn btn-success btn-xs">Task 5. </span> Recreate our initial dataset without an exclusion restriction and re-run our selection model.</p>
<pre><code>## --------------------------------------------
## Tobit 2 model (sample selection model)
## Maximum Likelihood estimation
## Newton-Raphson maximisation, 5 iterations
## Return code 1: gradient close to zero
## Log-Likelihood: -1697.967 
## 2000 observations (993 censored and 1007 observed)
## 6 free parameters (df = 1994)
## Probit selection equation:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.03290    0.05337   0.616    0.538    
## xs           1.04249    0.04719  22.089   &lt;2e-16 ***
## Outcome equation:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.09054    0.07100  -1.275    0.202    
## xs           1.03690    0.02347  44.184   &lt;2e-16 ***
##    Error terms:
##       Estimate Std. Error t value Pr(&gt;|t|)    
## sigma  0.96664    0.02345   41.23   &lt;2e-16 ***
## rho   -0.69351    0.06665  -10.40   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## --------------------------------------------</code></pre>
<p>We can see that the standard errors got much smaller because of this. re-doing our plot of the inverse mills ratio values implied by our dataset:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">df<span class="op">$</span>xsbeta =<span class="st"> </span><span class="kw">coef</span>(m)[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span><span class="kw">coef</span>(m)[<span class="dv">2</span>]<span class="op">*</span>xs</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">mi2 &lt;-<span class="st"> </span>mi <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x=</span>xsbeta,<span class="dt">y=</span><span class="kw">mills</span>(xsbeta)),<span class="dt">data=</span>df)</a>
<a class="sourceLine" id="cb6-3" data-line-number="3">mi2</a></code></pre></div>
<p><img src="lab-selection_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Also in terms of severity of selection, this issue is much differnt. To see this:</p>
<p><span class="btn btn-success btn-xs">Task 6. </span> Redo your plot from Task 3.</p>
<p><img src="lab-selection_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
</div>
</div>
<div id="real-data" class="section level2">
<h2>Real Data</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw">head</span>(Mroz87)</a></code></pre></div>
<pre><code>##   lfp hours kids5 kids618 age educ   wage repwage hushrs husage huseduc
## 1   1  1610     1       0  32   12 3.3540    2.65   2708     34      12
## 2   1  1656     0       2  30   12 1.3889    2.65   2310     30       9
## 3   1  1980     1       3  35   12 4.5455    4.04   3072     40      12
## 4   1   456     0       3  34   12 1.0965    3.25   1920     53      10
## 5   1  1568     1       2  31   14 4.5918    3.60   2000     32      12
## 6   1  2032     0       0  54   12 4.7421    4.70   1040     57      11
##   huswage faminc    mtr motheduc fatheduc unem city exper  nwifeinc
## 1  4.0288  16310 0.7215       12        7  5.0    0    14 10.910060
## 2  8.4416  21800 0.6615        7        7 11.0    1     5 19.499981
## 3  3.5807  21040 0.6915       12        7  5.0    0    15 12.039910
## 4  3.5417   7300 0.7815        7        7  5.0    0     6  6.799996
## 5 10.0000  27300 0.6215       12       14  9.5    1     7 20.100058
## 6  6.7106  19495 0.6915       14        7  7.5    1    33  9.859054
##   wifecoll huscoll  kids
## 1    FALSE   FALSE  TRUE
## 2    FALSE   FALSE  TRUE
## 3    FALSE   FALSE  TRUE
## 4    FALSE   FALSE  TRUE
## 5     TRUE   FALSE  TRUE
## 6    FALSE   FALSE FALSE</code></pre>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1">greeneTS &lt;-<span class="st"> </span><span class="kw">heckit</span>(<span class="dt">selection =</span> lfp <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(age<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>faminc <span class="op">+</span><span class="st"> </span>kids <span class="op">+</span><span class="st"> </span>educ,<span class="dt">outcome=</span> wage <span class="op">~</span><span class="st"> </span>exper <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(exper<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>educ <span class="op">+</span><span class="st"> </span>city, <span class="dt">data =</span> Mroz87)</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">greeneML &lt;-<span class="st"> </span><span class="kw">selection</span>(lfp <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(age<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>faminc <span class="op">+</span><span class="st"> </span>kids <span class="op">+</span><span class="st"> </span>educ,wage <span class="op">~</span><span class="st"> </span>exper <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(exper<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>educ <span class="op">+</span><span class="st"> </span>city, <span class="dt">data =</span> Mroz87,<span class="dt">maxMethod =</span> <span class="st">&quot;BHHH&quot;</span>, <span class="dt">iterlim =</span> <span class="dv">500</span>)</a>
<a class="sourceLine" id="cb9-3" data-line-number="3"></a>
<a class="sourceLine" id="cb9-4" data-line-number="4"><span class="kw">summary</span>(greeneTS)</a></code></pre></div>
<pre><code>## --------------------------------------------
## Tobit 2 model (sample selection model)
## 2-step Heckman / heckit estimation
## 753 observations (325 censored and 428 observed)
## 14 free parameters (df = 740)
## Probit selection equation:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -4.157e+00  1.402e+00  -2.965 0.003127 ** 
## age          1.854e-01  6.597e-02   2.810 0.005078 ** 
## I(age^2)    -2.426e-03  7.735e-04  -3.136 0.001780 ** 
## faminc       4.580e-06  4.206e-06   1.089 0.276544    
## kidsTRUE    -4.490e-01  1.309e-01  -3.430 0.000638 ***
## educ         9.818e-02  2.298e-02   4.272 2.19e-05 ***
## Outcome equation:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.9712003  2.0593505  -0.472    0.637    
## exper        0.0210610  0.0624646   0.337    0.736    
## I(exper^2)   0.0001371  0.0018782   0.073    0.942    
## educ         0.4170174  0.1002497   4.160 3.56e-05 ***
## city         0.4438379  0.3158984   1.405    0.160    
## Multiple R-Squared:0.1264,   Adjusted R-Squared:0.116
##    Error terms:
##               Estimate Std. Error t value Pr(&gt;|t|)
## invMillsRatio   -1.098      1.266  -0.867    0.386
## sigma            3.200         NA      NA       NA
## rho             -0.343         NA      NA       NA
## --------------------------------------------</code></pre>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">summary</span>(greeneML)</a></code></pre></div>
<pre><code>## --------------------------------------------
## Tobit 2 model (sample selection model)
## Maximum Likelihood estimation
## BHHH maximisation, 62 iterations
## Return code 2: successive function values within tolerance limit
## Log-Likelihood: -1581.259 
## 753 observations (325 censored and 428 observed)
## 13 free parameters (df = 740)
## Probit selection equation:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -4.120e+00  1.410e+00  -2.921  0.00359 ** 
## age          1.840e-01  6.584e-02   2.795  0.00532 ** 
## I(age^2)    -2.409e-03  7.735e-04  -3.115  0.00191 ** 
## faminc       5.676e-06  3.890e-06   1.459  0.14493    
## kidsTRUE    -4.507e-01  1.367e-01  -3.298  0.00102 ** 
## educ         9.533e-02  2.400e-02   3.973  7.8e-05 ***
## Outcome equation:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -1.9537242  1.6745690  -1.167    0.244    
## exper        0.0284295  0.0753989   0.377    0.706    
## I(exper^2)  -0.0001151  0.0023339  -0.049    0.961    
## educ         0.4562471  0.0959626   4.754 2.39e-06 ***
## city         0.4451424  0.4255420   1.046    0.296    
##    Error terms:
##       Estimate Std. Error t value Pr(&gt;|t|)    
## sigma  3.10350    0.08368  37.088   &lt;2e-16 ***
## rho   -0.13328    0.22296  -0.598     0.55    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## --------------------------------------------</code></pre>
<div id="role-of-joint-normality-assumption" class="section level3">
<h3>Role of Joint Normality Assumption</h3>
<p>We have in general for selected observations:</p>
<p><span class="math display">\[
y_i^o = \beta^o x_i^o + g(\beta^s x^s) + u_i^o
\]</span></p>
<p>i.e. if we don’t want to make the joint normality assumption, we just need a way to handle this function <span class="math inline">\(g\)</span>. In this case, an exclusion restriction is <strong>indepensable</strong>, because we do not know the shape of <span class="math inline">\(g\)</span>, hence cannot rely on nonlinearities.</p>
</div>
<div id="robinsons-solution" class="section level3">
<h3>Robinson’s solution</h3>
<p>A semiparametric solution to this problem is to realize that, by taking expectations on the previous equation, one gets</p>
<p><span class="math display">\[
E[y_i^o|\beta^s x^s] = \beta^o E[x_i^o |\beta^s x^s] + g(\beta^s x^s) 
\]</span> The Robinson (1988) solution is to just substract the latter from the former to get</p>
<p><span class="math display">\[
y_i^o - E[y_i^o|\beta^s x^s] = \beta^o [x_i^o - E[x_i^o |\beta^s x^s] ] + u_i^o
\]</span></p>
<p>The idea is then to replace <span class="math inline">\(E[y_i^o|\beta^s x^s]\)</span> and <span class="math inline">\(E[x_i^o|\beta^s x^s]\)</span> by non-parametric kernel estimates, and estimate <span class="math inline">\(\beta^o\)</span> in this way.</p>
</div>
</div>

<!--<a href="https://github.com/you"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://camo.githubusercontent.com/652c5b9acfaddf3a9c326fa6bde407b87f7be0f4/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f72696768745f6f72616e67655f6666373630302e706e67" alt="Fork me on GitHub" data-canonical-src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png"></a> -->
<a class="github-fork-ribbon right-bottom fixed" href="https://github.com/floswald/ScPo-Labor" title="Fork me on GitHub">Fork me on GitHub</a>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
